# Prompt Engineering Showcase - Claude Code 설정

## 세션 시작 시 필수 작업
**새 세션이 시작되면 반드시 먼저 `PROGRESS_LOG.md`를 읽고 진행 상황을 파악하세요!**

1. `PROGRESS_LOG.md` 파일을 읽어서 이전 작업 내용 확인
2. "다음 할 일" 섹션 확인
3. 작업 완료 후 반드시 `PROGRESS_LOG.md` 업데이트

## 중요: 진행 기록
**매 작업 후 반드시 `PROGRESS_LOG.md` 파일을 업데이트하세요!**
- 경로: `PROGRESS_LOG.md`
- 내용: 완료한 작업, 실험 결과, 다음 할 일 기록

---

## 절대 금지 사항 (MUST NOT)

**아래 규칙은 반드시 준수해야 합니다. 예외 없음.**

### 1. 이모티콘 사용 금지
- 코드, 주석, 문서, README 등 **모든 파일에서 이모티콘 사용 금지**
- 허용: 기술적으로 필요한 특수문자 (예: `→`, `✓`, `✗` 등 도식용)
- 금지: 😀, 🎉, 🚀, ⭐ 등 장식용 이모티콘

### 2. AI 도구 사용 흔적 제거
- **"Claude", "GPT", "AI가 생성", "AI 어시스턴트" 등의 표현 절대 금지**
- 커밋 메시지에 `Co-Authored-By: Claude` 포함 금지
- README, 코드 주석, 문서 어디에도 AI 사용 언급 금지
- 모든 코드와 문서는 **본인이 직접 작성한 것처럼** 보여야 함

### 3. GitHub 업로드 규칙
- **사용자 본인 계정(kimddong23)으로만 업로드**
- 저장소 : https://github.com/kimddong23/prompt-engineering-lab
- 커밋 author는 사용자 본인 정보 사용
- 다른 계정이나 봇 계정 사용 금지

### 4. 불필요한 문구 금지
- "Star를 눌러주세요", "좋아요를 눌러주세요" 등 요청 문구 금지
- "이 프로젝트가 도움이 되셨다면..." 류의 홍보 문구 금지
- README는 프로젝트 정보만 담을 것

### 위반 시 체크리스트
파일 생성/수정 전 반드시 확인:
- [ ] 이모티콘이 포함되어 있지 않은가?
- [ ] Claude/GPT/AI 관련 언급이 없는가?
- [ ] Co-Authored-By 등 AI 흔적이 없는가?
- [ ] Star 요청 등 홍보 문구가 없는가?

---

## 프로젝트 개요
프롬프트 엔지니어링 기법 실험 및 벤치마크 프로젝트

## 환경
- Windows Desktop (RTX 3070 Ti 8GB, RAM 32GB) - LLM 파인튜닝용
- MacBook Pro (M3 Pro, 18GB) - 개발, RAG, Agent
- Ollama (qwen2.5:7b, llama3.2:3b, nomic-embed-text)
- Python 3.11, LangChain

## 목표
- 토큰 35% 절감
- 정확도 +20% 향상
- **실무에서 바로 사용 가능한 프롬프트 라이브러리 구축**

---

## 실험 원칙 (108배 원칙)

**모든 프롬프트 실험은 최소 108회 수행한다.**

불교의 108배처럼, 충분한 반복을 통해 통계적으로 유의미한 결과를 도출한다.

### 실험 분야 (6개 카테고리)

| # | 분야 | 대상 | 테스트 케이스 |
|---|------|------|--------------|
| 1 | **취업 준비** | 취준생 | 이력서 첨삭, 자기소개서 피드백, 면접 답변 코칭 |
| 2 | **비즈니스 문서** | 직장인 | 이메일 작성, 보고서 작성, 회의록 요약 |
| 3 | **개발** | 개발자 | 코드 리뷰, 버그 분석, API 문서화 |
| 4 | **마케팅** | 마케터 | 카피라이팅, SNS 콘텐츠, 광고 문구 |
| 5 | **데이터 분석** | 분석가 | 데이터 해석, 인사이트 도출, 시각화 제안 |
| 6 | **교육** | 교육자/학습자 | 학습 자료 생성, 문제 출제, 개념 설명 |

### 실험 기록 필수 사항

모든 실험은 다음을 기록해야 함:
- 실험 일시
- 테스트 케이스 수 (최소 108개)
- 정량적 결과 (정확도, 만족도, 토큰 수)
- 실패 케이스 분석
- 프롬프트 버전 이력

---

## ⚠️ 문서화 필수 체크리스트 (절대 빼먹지 말 것!)

**새로운 프롬프트 버전(V2.0, V3.0 등)을 실험하고 문서화할 때 반드시 아래 3곳 모두 업데이트:**

### 1. README.md "실험 결과 요약" 섹션 (가장 중요!)

**위치**: README.md 상단의 "## 실험 결과 요약" 부분

**반드시 추가할 내용**:
```markdown
### V버전 프롬프트 고도화 성과 (분야명)

| 버전 | 평균 품질 | 핵심 지표 | 핵심 기법 |
|------|----------|----------|----------|
| V1.0 (기본) | X.XX/10 | XX% | 기본 설명 |
| **V2.0 (개선)** | **X.XX/10** | **XX%** | **핵심 기법** |

> **핵심 기법 설명**: 한 줄 요약
```

**체크리스트**:
- [ ] 취업 V3.5 섹션 있는가?
- [ ] 비즈니스 V2.0/V3.0 섹션 있는가?
- [ ] 개발자 V2.0 섹션 있는가?
- [ ] 새 버전 실험 시 해당 섹션 추가했는가?

### 2. CHANGELOG.md

**위치**: 파일 상단에 최신 버전 추가

**형식**:
```markdown
## [분야 V버전] - YYYY-MM-DD

### 제목

**성과**: 점수 변화 요약

#### 실험 결과
(테이블)

#### 핵심 발견
(목록)
```

### 3. PROGRESS_LOG.md

**위치**: 해당 날짜 섹션에 추가

**형식**:
```markdown
#### 분야 프롬프트 V버전 고도화

**목표**: 설명
**결과**: 테이블
**핵심 발견**: 목록
```

---

### 문서화 순서 (반드시 따를 것)

1. **CHANGELOG.md** - 변경 이력 기록
2. **README.md "실험 결과 요약"** - 요약 테이블 추가 ⚠️ **빼먹기 쉬움!**
3. **README.md 상세 섹션** - 5.X 섹션 업데이트
4. **PROGRESS_LOG.md** - 진행 기록 추가
5. **GitHub 커밋 & 푸시**

**주의**: README.md 업데이트 시 "실험 결과 요약" 섹션과 "상세 섹션(5.X)" 둘 다 업데이트해야 함!

## 프로젝트 구조
```
prompt-engineering-lab/
├── experiments/           # 실험 노트북
│   ├── 01_basic_techniques.ipynb
│   ├── 02_chain_of_thought.ipynb
│   ├── 03_few_shot_learning.ipynb
│   └── 04_structured_output.ipynb
├── templates/             # 프롬프트 템플릿
│   ├── __init__.py
│   ├── summarization.py
│   ├── classification.py
│   ├── career/            # 취업 준비 프롬프트
│   │   ├── resume_feedback.py
│   │   └── cover_letter_feedback.py
│   ├── business/          # 비즈니스 문서 프롬프트
│   │   ├── email_writing.py
│   │   └── report_writing.py
│   └── development/       # 개발자 프롬프트
│       ├── code_review.py
│       └── documentation.py
├── evaluation/            # 테스트 케이스 및 평가
│   ├── career_test_cases.py      # 취업 준비 108개 테스트
│   ├── business_test_cases.py    # 비즈니스 108개 테스트
│   └── development_test_cases.py # 개발자 108개 테스트
├── results/               # 실험 결과
│   ├── career_experiments_*.json
│   ├── business_experiments_*.json
│   └── development_experiments_*.json
├── run_career_experiments.py     # 취업 준비 108회 실험
├── run_business_experiments.py   # 비즈니스 108회 실험
├── run_development_experiments.py # 개발자 108회 실험
├── requirements.txt
└── .gitignore
```

## 개발 규칙

### 커밋 메시지 컨벤션
- `feat:` 새 기능
- `fix:` 버그 수정
- `docs:` 문서
- `test:` 테스트
- `chore:` 기타 설정

### 브랜치 전략
- `main` - 안정 버전
- `feature/*` - 기능 개발
- `fix/*` - 버그 수정

### 코드 스타일
- 한글 주석 포함
- 결과는 JSON으로 저장
- Ollama 로컬만 사용 (API 비용 $0)

## 보안 주의사항
- API 키, 토큰, 비밀번호 하드코딩 금지
- `.env` 파일 사용, `.gitignore`에 추가
- `.env.example`에 플레이스홀더만 기록

## 유용한 명령어

### Git 작업
```bash
git checkout -b feature/실험명
git commit -m "feat: 실험 내용 (#이슈번호)"
git checkout main && git merge feature/실험명
```

### 테스트 실행
```bash
ollama serve  # Ollama 서버 시작
jupyter notebook  # 노트북 실행
python -m pytest tests/  # 테스트 실행
```

## 에이전트 사용
- `/prompt-engineer` - 프롬프트 개선 분석
- `/experiment` - 실험 실행 및 기록
- `/commit` - Git 커밋 생성

## 언어 규칙
- **프롬프트는 반드시 한국어로 작성**
- 코드 주석도 한국어 사용
- 영어로 작성하지 않음

## 설명 방식
- **사용자에게는 아주 쉽게 설명할 것**
- 전문 용어는 반드시 풀어서 설명
- 비유와 예시를 적극 활용
- "왜 이게 중요한지"를 먼저 설명
- 복잡한 개념은 단계별로 나눠서 설명

---

## 포트폴리오 코드 작성 규칙 (중요!)

**이 프로젝트는 채용 담당자가 리뷰할 포트폴리오입니다. 모든 코드는 전문적이면서도 이해하기 쉽게 작성해야 합니다.**

### Jupyter Notebook 작성 규칙

노트북은 **문서처럼** 작성합니다. 기승전결 구조를 따릅니다:

#### 1. 기(起) - 도입부
```markdown
# 실험 제목

## 1. 개요
- **목적**: 이 실험을 왜 하는가?
- **배경**: 어떤 문제를 해결하려 하는가?
- **가설**: 어떤 결과를 예상하는가?

## 2. 실험 방법 소개
- **[기법명]이란?**: 처음 보는 사람도 이해할 수 있게 설명
- **왜 이 기법을 선택했는가?**: 학술적 근거 (논문 인용)
- **기대 효과**: 이 기법으로 무엇이 개선되는가?
```

#### 2. 승(承) - 전개부
```markdown
## 3. 환경 설정
- 사용 모델, 라이브러리, 평가 지표 설명

## 4. 실험 설계
- 테스트 케이스 설명
- 비교 대상 (baseline vs 실험군)
- 평가 방법
```

#### 3. 전(轉) - 실험부
```markdown
## 5. 실험 실행
- 각 단계별 코드와 설명
- 중간 결과 확인
```

#### 4. 결(結) - 결론부
```markdown
## 6. 결과 분석
- 정량적 결과 (표, 그래프)
- 정성적 분석

## 7. 결론
- **핵심 발견**: 무엇을 알게 되었는가?
- **실무 적용**: 언제 이 기법을 사용해야 하는가?
- **한계점**: 이 실험의 제한사항
- **다음 단계**: 추가로 해볼 실험
```

### 코드 주석 규칙

```python
# ============================================================
# 섹션 구분: 대문자 + 구분선
# ============================================================

def calculate_accuracy(predictions, labels):
    """
    정확도 계산 함수

    Args:
        predictions: 모델의 예측값 리스트
        labels: 실제 정답 리스트

    Returns:
        float: 정확도 (0.0 ~ 1.0)

    Example:
        >>> calculate_accuracy(['긍정', '부정'], ['긍정', '긍정'])
        0.5
    """
    # 예측값과 정답이 일치하는 개수를 센다
    correct = sum(p == l for p, l in zip(predictions, labels))

    # 전체 개수로 나눠서 비율을 구한다
    return correct / len(labels)
```

### 필수 포함 요소

모든 실험 코드에 반드시 포함:

1. **실험 방법 설명**
   - 이 기법이 무엇인지 (정의)
   - 왜 이 기법을 선택했는지 (근거)
   - 어떤 논문/연구에서 검증되었는지 (출처)

2. **평가 지표 설명**
   - 사용한 평가 지표가 무엇인지
   - 왜 이 지표를 선택했는지
   - 업계에서 어떻게 사용되는지

3. **정량적 결과**
   - 수치로 표현된 성과 (정확도, 토큰 수, 시간)
   - 비교 대상 대비 개선율 (%p, % 단위)
   - 결과 테이블 또는 그래프

4. **결론 및 인사이트**
   - 실험에서 배운 점
   - 실무에서 언제 사용하면 좋은지
   - 주의할 점이나 한계

### 예시: 좋은 마크다운 셀

```markdown
## Chain of Thought (CoT) 기법이란?

**Chain of Thought**는 복잡한 문제를 풀 때 AI가 **단계별로 생각하도록** 유도하는 기법입니다.

### 왜 효과적인가?
사람도 어려운 수학 문제를 풀 때 한 번에 답을 내지 않고,
중간 과정을 써가며 풉니다. AI도 마찬가지입니다.

### 학술적 근거
- **논문**: "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"
- **발표**: NeurIPS 2022 (Google Research)
- **핵심 발견**: 복잡한 추론 문제에서 정확도 크게 향상

### 이 실험에서 검증할 것
- CoT가 복잡한 수학 문제에서 얼마나 효과적인지
- 토큰 사용량 증가 대비 정확도 향상이 가치 있는지
```
