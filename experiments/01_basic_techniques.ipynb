{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 실험 01: 기본 프롬프트 vs 구조화 프롬프트\n",
        "\n",
        "**프롬프트 엔지니어링의 가장 기본적인 기법을 검증하는 실험**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 개요\n",
        "\n",
        "### 목적\n",
        "프롬프트의 **구조화**가 LLM(대규모 언어 모델)의 응답 품질에 어떤 영향을 미치는지 검증합니다.\n",
        "\n",
        "### 배경\n",
        "LLM에게 질문할 때, 같은 내용을 물어도 **어떻게 물어보느냐**에 따라 답변의 품질이 달라집니다.\n",
        "\n",
        "예를 들어:\n",
        "- ❌ \"이거 요약해줘\" → 모호함\n",
        "- ✅ \"아래 텍스트를 2문장으로 요약하세요. 핵심 정보만 포함하세요.\" → 명확함\n",
        "\n",
        "### 가설\n",
        "구조화된 프롬프트(마크다운 헤딩, 명확한 지시사항)를 사용하면:\n",
        "1. 응답의 **일관성**이 높아질 것이다\n",
        "2. 불필요한 출력이 줄어 **토큰 효율성**이 개선될 것이다\n",
        "3. 원하는 형식의 답변을 받을 확률이 높아질 것이다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 구조화 프롬프트란?\n",
        "\n",
        "### 정의\n",
        "**구조화 프롬프트(Structured Prompting)**는 프롬프트를 논리적인 섹션으로 나누어 작성하는 기법입니다.\n",
        "\n",
        "### 핵심 요소\n",
        "| 요소 | 설명 | 예시 |\n",
        "|------|------|------|\n",
        "| 역할 정의 | AI의 역할을 명시 | \"당신은 전문 번역가입니다\" |\n",
        "| 지시사항 | 수행할 작업을 명확히 | \"2문장으로 요약하세요\" |\n",
        "| 규칙/제약 | 지켜야 할 조건 | \"원문에 없는 내용 추가 금지\" |\n",
        "| 입력 데이터 | 처리할 데이터 | 요약할 텍스트 |\n",
        "| 출력 형식 | 원하는 응답 형식 | \"JSON 형식으로 출력\" |\n",
        "\n",
        "### 왜 효과적인가?\n",
        "1. **명확성**: AI가 무엇을 해야 하는지 정확히 이해\n",
        "2. **일관성**: 같은 프롬프트로 일관된 결과 획득\n",
        "3. **제어 가능성**: 출력 형식과 길이를 조절 가능\n",
        "\n",
        "### 학술적 근거\n",
        "- OpenAI의 [Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)에서 권장하는 best practice\n",
        "- Google의 PALM 2 논문에서도 구조화된 프롬프트의 효과성 검증"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 환경 설정\n",
        "\n",
        "### 사용 기술\n",
        "| 항목 | 값 | 설명 |\n",
        "|------|------|------|\n",
        "| 모델 | qwen2.5:7b | Alibaba의 오픈소스 LLM (7B 파라미터) |\n",
        "| 프레임워크 | LangChain | LLM 애플리케이션 개발 프레임워크 |\n",
        "| 토큰 계산 | tiktoken | OpenAI의 토큰화 라이브러리 |\n",
        "| 실행 환경 | Ollama | 로컬 LLM 실행 도구 |\n",
        "\n",
        "### 평가 지표\n",
        "| 지표 | 설명 | 중요도 |\n",
        "|------|------|--------|\n",
        "| 토큰 수 | 입력+출력 토큰의 합 | 비용과 직결 |\n",
        "| 응답 시간 | API 호출부터 응답까지 | 사용자 경험 |\n",
        "| 응답 품질 | 지시사항 준수 여부 | 정확성 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 환경 설정 및 라이브러리 임포트\n",
        "# ============================================================\n",
        "\n",
        "from langchain_ollama import ChatOllama\n",
        "import tiktoken\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# LLM 초기화\n",
        "# - model: 사용할 모델명\n",
        "# - temperature: 0으로 설정하여 결정적(deterministic) 출력 보장\n",
        "llm = ChatOllama(model=\"qwen2.5:7b\", temperature=0)\n",
        "\n",
        "# 토큰 카운터 초기화\n",
        "# - tiktoken은 OpenAI의 토크나이저로, 업계 표준으로 사용됨\n",
        "encoder = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "\n",
        "print(\"환경 설정 완료\")\n",
        "print(f\"- 모델: qwen2.5:7b\")\n",
        "print(f\"- Temperature: 0 (결정적 출력)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 유틸리티 함수 정의\n",
        "# ============================================================\n",
        "\n",
        "def count_tokens(text: str) -> int:\n",
        "    \"\"\"\n",
        "    텍스트의 토큰 수를 계산합니다.\n",
        "    \n",
        "    토큰이란?\n",
        "    - LLM이 텍스트를 처리하는 최소 단위\n",
        "    - 영어: 약 4글자 = 1토큰\n",
        "    - 한국어: 약 1-2글자 = 1토큰 (더 비효율적)\n",
        "    \n",
        "    Args:\n",
        "        text: 토큰 수를 계산할 텍스트\n",
        "    \n",
        "    Returns:\n",
        "        int: 토큰 수\n",
        "    \"\"\"\n",
        "    return len(encoder.encode(text))\n",
        "\n",
        "\n",
        "def run_prompt(prompt: str, name: str = \"\") -> dict:\n",
        "    \"\"\"\n",
        "    프롬프트를 실행하고 결과를 측정합니다.\n",
        "    \n",
        "    측정 항목:\n",
        "    1. 입력 토큰 수: 프롬프트의 토큰 수\n",
        "    2. 출력 토큰 수: 응답의 토큰 수\n",
        "    3. 응답 시간: 실행에 걸린 시간(초)\n",
        "    \n",
        "    Args:\n",
        "        prompt: 실행할 프롬프트\n",
        "        name: 실험 이름 (로깅용)\n",
        "    \n",
        "    Returns:\n",
        "        dict: 측정 결과와 응답 내용\n",
        "    \"\"\"\n",
        "    # 시작 시간 기록\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # LLM 호출\n",
        "    response = llm.invoke(prompt)\n",
        "    \n",
        "    # 종료 시간 기록\n",
        "    elapsed_time = time.time() - start_time\n",
        "    \n",
        "    return {\n",
        "        \"name\": name,\n",
        "        \"input_tokens\": count_tokens(prompt),\n",
        "        \"output_tokens\": count_tokens(response.content),\n",
        "        \"total_tokens\": count_tokens(prompt) + count_tokens(response.content),\n",
        "        \"time\": round(elapsed_time, 2),\n",
        "        \"response\": response.content\n",
        "    }\n",
        "\n",
        "\n",
        "print(\"유틸리티 함수 정의 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 실험 설계\n",
        "\n",
        "### 테스트 데이터\n",
        "AI와 딥러닝에 관한 4문장짜리 텍스트를 사용합니다.\n",
        "\n",
        "### 비교 대상\n",
        "| 프롬프트 유형 | 특징 |\n",
        "|--------------|------|\n",
        "| 기본 프롬프트 | 단순히 \"요약해줘\"라고 요청 |\n",
        "| 구조화 프롬프트 | 마크다운 헤딩 + 명확한 규칙 + 출력 형식 지정 |\n",
        "\n",
        "### 평가 방법\n",
        "1. **토큰 효율성**: 동일한 작업에 필요한 토큰 수 비교\n",
        "2. **응답 품질**: 지시사항(2문장 요약)을 얼마나 잘 따르는지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 테스트 데이터 준비\n",
        "# ============================================================\n",
        "\n",
        "# 요약 대상 텍스트 (AI에 관한 설명문)\n",
        "test_text = \"\"\"\n",
        "인공지능(AI)은 인간의 학습능력, 추론능력, 지각능력을 인공적으로 구현한 컴퓨터 시스템이다.\n",
        "최근 딥러닝 기술의 발전으로 자연어 처리, 이미지 인식, 음성 인식 등 다양한 분야에서 \n",
        "인간 수준 또는 그 이상의 성능을 보이고 있다. 특히 대규모 언어 모델(LLM)의 등장으로\n",
        "챗봇, 문서 요약, 코드 생성 등 다양한 응용 분야가 확대되고 있다.\n",
        "\"\"\".strip()\n",
        "\n",
        "print(\"테스트 텍스트:\")\n",
        "print(\"-\" * 50)\n",
        "print(test_text)\n",
        "print(\"-\" * 50)\n",
        "print(f\"텍스트 길이: {len(test_text)}자, {count_tokens(test_text)}토큰\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 실험 실행\n",
        "\n",
        "### 5.1 기본 프롬프트 vs 구조화 프롬프트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 실험 5.1: 기본 프롬프트\n",
        "# ============================================================\n",
        "# 특징: 단순하고 직관적이지만, 출력 형식이 모호함\n",
        "\n",
        "basic_prompt = f\"다음 글을 요약해줘: {test_text}\"\n",
        "\n",
        "print(\"[기본 프롬프트]\")\n",
        "print(basic_prompt)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 실험 5.1: 구조화 프롬프트\n",
        "# ============================================================\n",
        "# 특징: \n",
        "# - 마크다운 헤딩(###)으로 섹션 구분\n",
        "# - 명확한 규칙 제시\n",
        "# - 출력 위치 지정\n",
        "\n",
        "structured_prompt = f\"\"\"### 지시사항\n",
        "아래 텍스트를 2문장으로 요약하세요.\n",
        "\n",
        "### 규칙\n",
        "- 핵심 정보만 포함\n",
        "- 원문에 없는 내용 추가 금지\n",
        "\n",
        "### 텍스트\n",
        "{test_text}\n",
        "\n",
        "### 요약\"\"\"\n",
        "\n",
        "print(\"[구조화 프롬프트]\")\n",
        "print(structured_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 두 프롬프트 실행 및 결과 비교\n",
        "# ============================================================\n",
        "\n",
        "# 실행\n",
        "result_basic = run_prompt(basic_prompt, \"기본\")\n",
        "result_structured = run_prompt(structured_prompt, \"구조화\")\n",
        "\n",
        "# 결과 출력\n",
        "print(\"=\" * 60)\n",
        "print(\"실험 결과: 기본 프롬프트 vs 구조화 프롬프트\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\n[기본 프롬프트 결과]\")\n",
        "print(f\"  입력 토큰: {result_basic['input_tokens']}\")\n",
        "print(f\"  출력 토큰: {result_basic['output_tokens']}\")\n",
        "print(f\"  응답 시간: {result_basic['time']}초\")\n",
        "print(f\"  응답 내용:\")\n",
        "print(f\"  {result_basic['response']}\")\n",
        "\n",
        "print(\"\\n[구조화 프롬프트 결과]\")\n",
        "print(f\"  입력 토큰: {result_structured['input_tokens']}\")\n",
        "print(f\"  출력 토큰: {result_structured['output_tokens']}\")\n",
        "print(f\"  응답 시간: {result_structured['time']}초\")\n",
        "print(f\"  응답 내용:\")\n",
        "print(f\"  {result_structured['response']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 다양한 구조화 스타일 비교\n",
        "\n",
        "구조화 프롬프트도 여러 스타일이 있습니다:\n",
        "\n",
        "| 스타일 | 특징 | 장점 |\n",
        "|--------|------|------|\n",
        "| Markdown | 헤딩(#, ##, ###) 사용 | 가독성 좋음 |\n",
        "| XML | 태그(<tag>) 사용 | 파싱하기 쉬움 |\n",
        "| JSON | 키-값 구조 | 프로그래밍 친화적 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 실험 5.2: 다양한 구조화 스타일 비교\n",
        "# ============================================================\n",
        "\n",
        "# 스타일 1: Markdown 스타일\n",
        "markdown_prompt = f\"\"\"# 요약 작업\n",
        "\n",
        "## 지시사항\n",
        "2문장으로 요약하세요.\n",
        "\n",
        "## 텍스트\n",
        "{test_text}\n",
        "\n",
        "## 요약\"\"\"\n",
        "\n",
        "# 스타일 2: XML 스타일\n",
        "xml_prompt = f\"\"\"<instruction>2문장으로 요약하세요.</instruction>\n",
        "\n",
        "<text>\n",
        "{test_text}\n",
        "</text>\n",
        "\n",
        "<summary>\"\"\"\n",
        "\n",
        "# 스타일 3: JSON 스타일\n",
        "json_prompt = f\"\"\"입력:\n",
        "{{\n",
        "    \"task\": \"summarize\",\n",
        "    \"max_sentences\": 2,\n",
        "    \"text\": \"{test_text}\"\n",
        "}}\n",
        "\n",
        "출력 (요약만):\"\"\"\n",
        "\n",
        "# 실행\n",
        "results_style = [\n",
        "    run_prompt(markdown_prompt, \"Markdown\"),\n",
        "    run_prompt(xml_prompt, \"XML\"),\n",
        "    run_prompt(json_prompt, \"JSON\")\n",
        "]\n",
        "\n",
        "# 결과 출력\n",
        "print(\"=\" * 60)\n",
        "print(\"스타일별 비교 결과\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"{'스타일':<12} {'입력 토큰':<12} {'출력 토큰':<12} {'시간':<10}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for r in results_style:\n",
        "    print(f\"{r['name']:<12} {r['input_tokens']:<12} {r['output_tokens']:<12} {r['time']}초\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 결과 분석\n",
        "\n",
        "### 6.1 정량적 결과"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 결과 분석: 정량적 비교\n",
        "# ============================================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"정량적 결과 요약\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 기본 vs 구조화 비교\n",
        "token_diff = result_structured['output_tokens'] - result_basic['output_tokens']\n",
        "token_change = (token_diff / result_basic['output_tokens']) * 100 if result_basic['output_tokens'] > 0 else 0\n",
        "\n",
        "time_diff = result_structured['time'] - result_basic['time']\n",
        "time_change = (time_diff / result_basic['time']) * 100 if result_basic['time'] > 0 else 0\n",
        "\n",
        "print(\"\\n[기본 vs 구조화 프롬프트]\")\n",
        "print(f\"┌{'─'*20}┬{'─'*15}┬{'─'*15}┬{'─'*15}┐\")\n",
        "print(f\"│ {'항목':<18} │ {'기본':<13} │ {'구조화':<13} │ {'변화':<13} │\")\n",
        "print(f\"├{'─'*20}┼{'─'*15}┼{'─'*15}┼{'─'*15}┤\")\n",
        "print(f\"│ {'출력 토큰':<18} │ {result_basic['output_tokens']:<13} │ {result_structured['output_tokens']:<13} │ {token_change:>+10.1f}% │\")\n",
        "print(f\"│ {'응답 시간(초)':<18} │ {result_basic['time']:<13} │ {result_structured['time']:<13} │ {time_change:>+10.1f}% │\")\n",
        "print(f\"└{'─'*20}┴{'─'*15}┴{'─'*15}┴{'─'*15}┘\")\n",
        "\n",
        "print(\"\\n[스타일별 비교]\")\n",
        "print(f\"┌{'─'*12}┬{'─'*12}┬{'─'*12}┬{'─'*10}┐\")\n",
        "print(f\"│ {'스타일':<10} │ {'입력토큰':<10} │ {'출력토큰':<10} │ {'시간':<8} │\")\n",
        "print(f\"├{'─'*12}┼{'─'*12}┼{'─'*12}┼{'─'*10}┤\")\n",
        "for r in results_style:\n",
        "    print(f\"│ {r['name']:<10} │ {r['input_tokens']:<10} │ {r['output_tokens']:<10} │ {r['time']:<6}초 │\")\n",
        "print(f\"└{'─'*12}┴{'─'*12}┴{'─'*12}┴{'─'*10}┘\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2 정성적 분석\n",
        "\n",
        "**기본 프롬프트의 응답**\n",
        "- 요약 길이가 일정하지 않을 수 있음\n",
        "- \"~입니다\" 등 불필요한 서술 포함 가능\n",
        "\n",
        "**구조화 프롬프트의 응답**\n",
        "- \"2문장\"이라는 명확한 제약 준수\n",
        "- 핵심 정보만 포함하려는 경향"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 결론\n",
        "\n",
        "### 핵심 발견\n",
        "\n",
        "1. **구조화 프롬프트의 장점**\n",
        "   - 명확한 지시사항으로 일관된 출력 형식 확보\n",
        "   - 규칙을 명시하여 원치 않는 내용 방지\n",
        "\n",
        "2. **스타일별 차이**\n",
        "   - Markdown: 가독성 좋고 범용적\n",
        "   - XML: 프로그래밍 통합 시 유리\n",
        "   - JSON: API 응답 생성 시 적합\n",
        "\n",
        "### 실무 적용 가이드\n",
        "\n",
        "| 상황 | 권장 방식 |\n",
        "|------|----------|\n",
        "| 단순 질의응답 | 기본 프롬프트 |\n",
        "| 특정 형식 필요 | 구조화 프롬프트 |\n",
        "| API 응답 생성 | JSON/XML 스타일 |\n",
        "| 문서 작성 | Markdown 스타일 |\n",
        "\n",
        "### 한계점\n",
        "- 단순 요약 작업에서는 차이가 크지 않을 수 있음\n",
        "- 복잡한 작업에서 더 큰 효과 예상\n",
        "\n",
        "### 다음 실험\n",
        "- Chain of Thought (단계별 사고) 기법 실험\n",
        "- 복잡한 추론 문제에서의 효과 검증"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 결과 저장\n",
        "# ============================================================\n",
        "\n",
        "experiment_results = {\n",
        "    \"experiment\": \"01_기본_프롬프트_vs_구조화_프롬프트\",\n",
        "    \"date\": datetime.now().isoformat(),\n",
        "    \"model\": \"qwen2.5:7b\",\n",
        "    \"hypothesis\": \"구조화 프롬프트가 일관성과 토큰 효율성을 개선한다\",\n",
        "    \"results\": {\n",
        "        \"basic_vs_structured\": {\n",
        "            \"basic\": {\n",
        "                \"input_tokens\": result_basic['input_tokens'],\n",
        "                \"output_tokens\": result_basic['output_tokens'],\n",
        "                \"time\": result_basic['time']\n",
        "            },\n",
        "            \"structured\": {\n",
        "                \"input_tokens\": result_structured['input_tokens'],\n",
        "                \"output_tokens\": result_structured['output_tokens'],\n",
        "                \"time\": result_structured['time']\n",
        "            },\n",
        "            \"comparison\": {\n",
        "                \"token_change\": f\"{token_change:+.1f}%\",\n",
        "                \"time_change\": f\"{time_change:+.1f}%\"\n",
        "            }\n",
        "        },\n",
        "        \"style_comparison\": [\n",
        "            {\"style\": r['name'], \"input_tokens\": r['input_tokens'], \n",
        "             \"output_tokens\": r['output_tokens'], \"time\": r['time']}\n",
        "            for r in results_style\n",
        "        ]\n",
        "    },\n",
        "    \"conclusion\": {\n",
        "        \"finding\": \"구조화 프롬프트는 출력 형식 제어에 효과적\",\n",
        "        \"recommendation\": \"특정 형식이 필요한 작업에 구조화 프롬프트 권장\",\n",
        "        \"limitation\": \"단순 작업에서는 차이가 크지 않음\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# JSON 파일로 저장\n",
        "with open(\"../results/01_basic_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(experiment_results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"실험 결과가 저장되었습니다: results/01_basic_results.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 참고 자료\n",
        "\n",
        "1. OpenAI Prompt Engineering Guide: https://platform.openai.com/docs/guides/prompt-engineering\n",
        "2. LangChain Documentation: https://python.langchain.com/docs/\n",
        "3. tiktoken: https://github.com/openai/tiktoken\n",
        "\n",
        "---\n",
        "\n",
        "*이 실험은 프롬프트 엔지니어링 포트폴리오 프로젝트의 일부입니다.*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
